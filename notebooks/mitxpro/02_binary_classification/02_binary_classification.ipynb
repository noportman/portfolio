{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MGL2uOuhNoYV"
   },
   "source": [
    "# Binary Classification on Tabular Data - Predicting Abnormal ECG Scans\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R08X1ZTM7Q7R"
   },
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/snowport/snowport.github.io/blob/main/docs/notebooks/mitxpro/02_binary_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m0fkGCQNlzc"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook, you will train an autoencoder to detect anomalies on the ECG5000 dataset. This dataset contains 5,000 Electrocardiograms, each with 140 data points. You will use a simplified version of the dataset, where each example has been labeled either 0 (corresponding to an abnormal rhythm), or 1 (corresponding to a normal rhythm). You are interested in identifying the abnormal rhythms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8us-geJNrrP"
   },
   "source": [
    "## Technical preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-5CngkPJs8N"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# initialize the seeds of different random number generators so that the\n",
    "# results will be the same every time the notebook is run\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0c6Oy0gNxD5"
   },
   "source": [
    "## Read in the data\n",
    "\n",
    "Conveniently, the dataset in CSV form has been made available online and we can load it into a Pandas dataframe with the very useful `pd.read_csv` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ngn4J7WJ9Br"
   },
   "outputs": [],
   "source": [
    "# Because each column of data represents a datapoint we will name the columns by the sequence of datapoints\n",
    "# (1,2,3...140)\n",
    "names = []\n",
    "for i in range(140):\n",
    "    names.append(i)\n",
    "# The last column will be the target or dependent variable\n",
    "names.append(\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbrLzn0GNu9C"
   },
   "source": [
    "Read in the data from http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv and set the column names from the list created in the box above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69e7I9U4J-eI"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv\", header=None\n",
    ")\n",
    "\n",
    "df.columns = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hg0SoQQhJ_mF",
    "outputId": "a5670d11-b901-47d4-8455-a2f7cab92f17"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "g7blr1l5KCM2",
    "outputId": "dc480586-c96b-4a56-b46f-887aa15e41cc"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OOvYP5QEN2hJ"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "This dataset only has numeric variables. For consistency sake, we will assign the column names to variable numerics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LRCqYc3KD85"
   },
   "outputs": [],
   "source": [
    "numerics = names\n",
    "\n",
    "# Remove the dependent variable\n",
    "numerics.remove(\"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59OT36o0KF9E",
    "outputId": "8b6eaee4-e330-4e9d-95d0-6dda64f4c607"
   },
   "outputs": [],
   "source": [
    "# Set the output to \"target_metrics\"\n",
    "target_metrics = df.Target.value_counts(normalize=True)\n",
    "print(target_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daMUPoXGN4mA"
   },
   "source": [
    "Extract the dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IF_RSWlhKHWB"
   },
   "outputs": [],
   "source": [
    "# set the dependent variables to 'y'\n",
    "y = df.pop(\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtSM3jC9N6x-"
   },
   "source": [
    "\n",
    "Before we normalize the numerics, let's split the data into an 80% training set and 20% test set (*why should we split **before** normalization?*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQ98B7TYLJXz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvnzP1g4MyaK"
   },
   "outputs": [],
   "source": [
    "# split into train and test sets with the following naming conventions:\n",
    "# X_train, X_test, y_train and y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gVzpUbd8N91U"
   },
   "source": [
    "OK, let's calculate the mean and standard deviation of every numeric variable in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LVC_38G3Mzb7",
    "outputId": "18dba448-9b59-4c3a-f5a4-667c87a4568c"
   },
   "outputs": [],
   "source": [
    "# Assign the means to \"means\" and standard deviation to \"sd\"\n",
    "means = X_train[numerics].mean()\n",
    "sd = X_train[numerics].std()\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StF7K6INOB5N"
   },
   "source": [
    "Let's normalize the train and test dataframes with these means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xiIH6RKKM0s5"
   },
   "outputs": [],
   "source": [
    "# Normalize X_train\n",
    "X_train[numerics] = (X_train[numerics] - means) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjeGnoNPM1p1"
   },
   "outputs": [],
   "source": [
    "# Normalize X_test\n",
    "X_test[numerics] = (X_test[numerics] - means) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "zgZrGpNHM3ld",
    "outputId": "9139523c-2399-47a1-b3ed-ec5c9bd05c14"
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEQ1Wv_6OGA0"
   },
   "source": [
    "The easiest way to feed data to Keras/Tensorflow is as Numpy arrays so we convert our two dataframes to Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSwABxJdM5GZ"
   },
   "outputs": [],
   "source": [
    "# Convert X_train and X_test to Numpy arrays\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztIqv5SqM7Xd",
    "outputId": "a29c3057-b52f-480a-aa74-78ef4bdf5569"
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaUEkDihM8hw",
    "outputId": "e44feba6-76e0-480a-b552-7f052b914c99"
   },
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPUha4P7NBJb"
   },
   "source": [
    "## Build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD_B8dueNFt7"
   },
   "source": [
    "### Define model in Keras\n",
    "\n",
    "Creating an NN  is usually just a few lines of Keras code.\n",
    "\n",
    "* We will start with a single hidden layer.\n",
    "* Since this is a *binary classification problem*, we will use a sigmoid activation in the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9pzwAN6M_H1"
   },
   "outputs": [],
   "source": [
    "# get the number of columns and assign it to \"num_columns\"\n",
    "\n",
    "num_columns = X_train.shape[1]\n",
    "\n",
    "# Define the input layer. assign it to \"input\"\n",
    "input = keras.Input(shape=(num_columns,), dtype=\"float32\")\n",
    "\n",
    "# Feed the input vector to the hidden layer. Call it \"h\"\n",
    "h = keras.layers.Dense(16, activation=\"relu\", name=\"Hidden\")(input)\n",
    "\n",
    "# Feed the output of the hidden layer to the output layer. Call it \"output\"\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"Output\")(h)\n",
    "\n",
    "# tell Keras that this (input,output) pair is your model. Call it \"model\"\n",
    "model = keras.Model(input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "id": "3fMS6UNRNPTM",
    "outputId": "4d6dc45c-c4dd-4176-c018-3dd71927e853"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yc8O98MMNQpc"
   },
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qMgPc5JHNS10"
   },
   "source": [
    "### Set optimization parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bp-OjU_NNUfp"
   },
   "source": [
    "Now that the model is defined, we need to tell Keras three things:\n",
    "\n",
    "*   What **loss function** to use - Since our output variable is binary, we will select the `binary_crossentropy` loss function.\n",
    "*   Which **optimizer** to use - we will use a 'flavor' of SGD called `adam` which is an excellent default choice\n",
    "*   What **metrics** you want Keras to report out - in classification problems like this one, `accuracy` is commonly used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EF-hI65NUO4"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxn98eWdNXD8"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "To kickoff training, we have to decide on three things:\n",
    "* The *batch size* - 32 is a good default\n",
    "* The number of *epochs* (i.e., how many passes through the training data). Start by setting this to 100, but you can experiment with different values.\n",
    "* Whether we want to use a validation set. This will be useful for overfitting detection and regularization via early stopping so we will ask Keras to automatically use 20% of the data points as a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z7eVZfydNZJT"
   },
   "outputs": [],
   "source": [
    "# Fit your model and assign the output to \"history\"\n",
    "history = model.fit(\n",
    "    X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdCSQmVINbhS",
    "outputId": "67b82067-707a-4159-b26c-5b8a9536b0ec"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "WD0auO73NcY1",
    "outputId": "6ddae892-de38-4782-e17e-371024e5e268"
   },
   "outputs": [],
   "source": [
    "loss_values = history_dict[\"loss\"]\n",
    "val_loss_values = history_dict[\"val_loss\"]\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "tcOkjBScNdyf",
    "outputId": "61e65c70-6e2e-4a89-a97d-186feda10f79"
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history_dict[\"accuracy\"]\n",
    "val_acc = history_dict[\"val_accuracy\"]\n",
    "plt.plot(epochs, acc, \"bo\", label=\"Training acc\")\n",
    "plt.plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS8iR5tTNfpT"
   },
   "source": [
    "## Evaluate the model\n",
    "\n",
    "Let's see **how well the model does on the test set**.\n",
    "\n",
    "`model.evaluate` is a very handy function to calculate the performance of your model on any dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHaJ8-XmNgKX",
    "outputId": "7ccb264e-0ac1-419a-9e79-a6dee9720087"
   },
   "outputs": [],
   "source": [
    "# Getting the results of your model for grading\n",
    "score, acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "vk0Wto1jNiP9",
    "outputId": "5ee43d61-187a-43df-ae17-662b3dbe180b"
   },
   "outputs": [],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "5JvDAkbKMC2_",
    "outputId": "dd88a6be-d5b8-4024-9f43-e11621501dd1"
   },
   "outputs": [],
   "source": [
    "# Selecting a specific row (e.g., row index 300)\n",
    "row_index = 300\n",
    "y_values = X_train[row_index, :]\n",
    "x_values = range(X_train.shape[1])  # X-axis: 0 to 139\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(x_values, y_values, marker=\"o\", linestyle=\"-\")\n",
    "plt.xlabel(\"X-Axis (Index)\")\n",
    "plt.ylabel(\"Y-Axis (Values)\")\n",
    "plt.title(f\"Plot of Row {row_index}\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faYbTVGMNH2H",
    "outputId": "11871a95-f023-4c03-8f4d-0b8287611315"
   },
   "outputs": [],
   "source": [
    "print(y_train[row_index])  # Result is abnormal scan for row_index=300"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
